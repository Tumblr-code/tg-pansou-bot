"""
Pansou API å®¢æˆ·ç«¯
"""
import asyncio
import html
import re
from typing import Optional, List, Dict, Any
import httpx
from structlog import get_logger

from config import settings

logger = get_logger()

# ç½‘ç›˜ç±»å‹ä¸­æ–‡æ˜ å°„
CLOUD_TYPE_NAMES = {
    "baidu": "ç™¾åº¦ç½‘ç›˜",
    "aliyun": "é˜¿é‡Œäº‘ç›˜",
    "quark": "å¤¸å…‹ç½‘ç›˜",
    "tianyi": "å¤©ç¿¼äº‘ç›˜",
    "uc": "UCç½‘ç›˜",
    "mobile": "ç§»åŠ¨äº‘ç›˜",
    "115": "115ç½‘ç›˜",
    "pikpak": "PikPak",
    "xunlei": "è¿…é›·ç½‘ç›˜",
    "123": "123ç½‘ç›˜",
    "magnet": "ç£åŠ›é“¾æ¥",
    "ed2k": "ç”µé©´é“¾æ¥",
    "others": "å…¶ä»–",
}

# ç½‘ç›˜ç±»å‹å›¾æ ‡
CLOUD_TYPE_ICONS = {
    "baidu": "ğŸ”´",
    "aliyun": "ğŸ”µ",
    "quark": "ğŸŸ ",
    "tianyi": "ğŸŸ¡",
    "uc": "ğŸŸ£",
    "mobile": "ğŸŸ¢",
    "115": "âš«",
    "pikpak": "ğŸ©·",
    "xunlei": "ğŸ”·",
    "123": "ğŸ”¶",
    "magnet": "ğŸ§²",
    "ed2k": "ğŸ“",
    "others": "ğŸ“",
}


class PansouClient:
    """Pansou API å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.base_url = settings.pansou_api_url.rstrip('/')
        self.timeout = settings.search_timeout
        self.headers = {}
        if settings.pansou_api_token:
            self.headers["Authorization"] = f"Bearer {settings.pansou_api_token}"
    
    def _get_client(self) -> httpx.AsyncClient:
        """åˆ›å»º HTTP å®¢æˆ·ç«¯ï¼ˆä¼˜åŒ–è¿æ¥é€Ÿåº¦ï¼‰"""
        proxy = None
        proxies = settings.get_proxies()
        if proxies:
            proxy = proxies.get('https://') or proxies.get('http://')
        
        # ä¼˜åŒ–è¶…æ—¶è®¾ç½®ï¼šè¿æ¥10ç§’ï¼Œè¯»å–45ç§’
        timeout = httpx.Timeout(
            connect=10.0,
            read=45.0,
            write=10.0,
            pool=10.0
        )
        
        # ä½¿ç”¨è¿æ¥æ± ä¼˜åŒ–æ€§èƒ½
        limits = httpx.Limits(
            max_keepalive_connections=10,
            max_connections=20,
            keepalive_expiry=30.0
        )
        
        return httpx.AsyncClient(
            timeout=timeout,
            proxy=proxy,
            headers=self.headers,
            limits=limits,
            http2=False  # å¯ç”¨ HTTP/2
        )
    
    async def search(
        self,
        keyword: str,
        channels: Optional[List[str]] = None,
        plugins: Optional[List[str]] = None,
        cloud_types: Optional[List[str]] = None,
        source_type: Optional[str] = None,
        filter_config: Optional[dict] = None,
        limit: int = 10,
        retries: int = 2
    ) -> Dict[str, Any]:
        """
        æœç´¢ç½‘ç›˜èµ„æºï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            channels: æœç´¢é¢‘é“åˆ—è¡¨
            plugins: æŒ‡å®šæ’ä»¶åˆ—è¡¨
            cloud_types: æŒ‡å®šç½‘ç›˜ç±»å‹
            source_type: æ¥æºç±»å‹ (all/tg/plugin)
            filter_config: è¿‡æ»¤é…ç½® {"include": [], "exclude": []}
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            retries: é‡è¯•æ¬¡æ•°
        
        Returns:
            æœç´¢ç»“æœ
        """
        url = f"{self.base_url}/api/search"
        
        payload = {
            "kw": keyword,
            "res": "merge",
            "src": source_type or "all",
        }
        
        if channels:
            payload["channels"] = channels
        if plugins:
            payload["plugins"] = plugins
        if cloud_types:
            payload["cloud_types"] = cloud_types
        if filter_config:
            payload["filter"] = filter_config
        
        last_error = None
        for attempt in range(retries + 1):
            try:
                async with self._get_client() as client:
                    # æœç´¢è¶…æ—¶è®¾ç½®ä¸º 60 ç§’
                    response = await client.post(url, json=payload, timeout=60)
                    response.raise_for_status()
                    data = response.json()
                
                if data.get("code") != 0:
                    logger.error("search_failed", code=data.get("code"), message=data.get("message"))
                    return {"error": data.get("message", "æœç´¢å¤±è´¥")}
                
                result = data.get("data", {})
                
                # åº”ç”¨æœ¬åœ°è¿‡æ»¤ï¼ˆäºŒæ¬¡è¿‡æ»¤ï¼‰
                if filter_config and result.get("merged_by_type"):
                    result["merged_by_type"] = self._apply_filter(
                        result["merged_by_type"], 
                        filter_config
                    )
                    # é‡æ–°è®¡ç®—æ€»æ•°
                    result["total"] = sum(
                        len(links) for links in result["merged_by_type"].values()
                    )
                
                return result
                
            except (httpx.ConnectError, httpx.TimeoutException, httpx.NetworkError) as e:
                last_error = e
                if attempt < retries:
                    logger.warning("search_retry", keyword=keyword, attempt=attempt + 1, error=str(e))
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                    continue
                else:
                    logger.error("search_failed_after_retries", keyword=keyword, error=str(e))
                    if isinstance(e, httpx.TimeoutException):
                        return {"error": "æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"}
                    return {"error": "ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"}
            except httpx.HTTPStatusError as e:
                logger.error("search_http_error", status=e.response.status_code, detail=str(e))
                return {"error": f"æœç´¢æœåŠ¡é”™è¯¯: HTTP {e.response.status_code}"}
            except Exception as e:
                logger.error("search_exception", error=str(e))
                return {"error": f"æœç´¢å‡ºé”™: {str(e)}"}
    
    def _apply_filter(
        self, 
        merged_by_type: Dict[str, List[dict]], 
        filter_config: dict
    ) -> Dict[str, List[dict]]:
        """åº”ç”¨è¿‡æ»¤é…ç½®åˆ°ç»“æœ"""
        include_list = filter_config.get("include", [])
        exclude_list = filter_config.get("exclude", [])
        
        if not include_list and not exclude_list:
            return merged_by_type
        
        filtered = {}
        for cloud_type, links in merged_by_type.items():
            filtered_links = []
            for link in links:
                note = link.get("note", "")
                url = link.get("url", "")
                text = f"{note} {url}".lower()
                
                # æ£€æŸ¥æ’é™¤è¯
                if exclude_list:
                    should_exclude = any(
                        excl.lower() in text for excl in exclude_list
                    )
                    if should_exclude:
                        continue
                
                # æ£€æŸ¥åŒ…å«è¯
                if include_list:
                    should_include = any(
                        incl.lower() in text for incl in include_list
                    )
                    if not should_include:
                        continue
                
                filtered_links.append(link)
            
            if filtered_links:
                filtered[cloud_type] = filtered_links
        
        return filtered
    
    async def health_check(self) -> bool:
        """æ£€æŸ¥ pansou æœåŠ¡æ˜¯å¦å¥åº·"""
        try:
            async with self._get_client() as client:
                response = await client.get(f"{self.base_url}/api/health", timeout=5)
                return response.status_code == 200
        except Exception:
            return False
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´æ ¼å¼é—®é¢˜çš„å­—ç¬¦"""
        if not text:
            return ""
        text = str(text)
        text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def get_type_buttons(self, results: Dict[str, Any]) -> List[List[Dict]]:
        """
        ç”Ÿæˆç½‘ç›˜ç±»å‹æŒ‰é’®é…ç½®
        
        Returns:
            æŒ‰é’®é…ç½®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ [text, callback_data]
        """
        merged_by_type = results.get("merged_by_type", {})
        if not merged_by_type:
            return []
        
        buttons = []
        for cloud_type, links in merged_by_type.items():
            if not links:
                continue
            
            icon = CLOUD_TYPE_ICONS.get(cloud_type, "ğŸ“")
            name = CLOUD_TYPE_NAMES.get(cloud_type, cloud_type)
            count = len(links)
            
            buttons.append({
                "text": f"{icon} {name} ({count})",
                "type": cloud_type,
                "count": count
            })
        
        # æŒ‰æ•°é‡æ’åº
        buttons.sort(key=lambda x: x["count"], reverse=True)
        return buttons
    
    def format_overview(self, results: Dict[str, Any], keyword: str) -> str:
        """
        æ ¼å¼åŒ–æœç´¢ç»“æœæ¦‚è§ˆ
        
        Args:
            results: API è¿”å›çš„ç»“æœ
            keyword: æœç´¢å…³é”®è¯
        
        Returns:
            æ¦‚è§ˆæ–‡æœ¬
        """
        if "error" in results:
            return f"âŒ æœç´¢å¤±è´¥: {results['error']}"
        
        merged_by_type = results.get("merged_by_type", {})
        total = results.get("total", 0)
        
        if not merged_by_type or total == 0:
            return f"ğŸ” æœªæ‰¾åˆ°ä¸ã€Œ{keyword}ã€ç›¸å…³çš„èµ„æº"
        
        lines = [
            f"ğŸ” æœç´¢ç»“æœ: {keyword}",
            f"ğŸ“Š å…±æ‰¾åˆ° {total} æ¡ç»“æœ",
            "",
            "ğŸ‘‡ è¯·é€‰æ‹©ç½‘ç›˜ç±»å‹æŸ¥çœ‹è¯¦ç»†èµ„æº:"
        ]
        
        return "\n".join(lines)
    
    def format_type_results(
        self, 
        results: Dict[str, Any], 
        keyword: str, 
        cloud_type: str,
        page: int = 1,
        per_page: int = 5
    ) -> str:
        """
        æ ¼å¼åŒ–æŒ‡å®šç½‘ç›˜ç±»å‹çš„ç»“æœ
        
        Args:
            results: API è¿”å›çš„ç»“æœ
            keyword: æœç´¢å…³é”®è¯
            cloud_type: ç½‘ç›˜ç±»å‹
            page: é¡µç 
            per_page: æ¯é¡µæ•°é‡
        
        Returns:
            æ ¼å¼åŒ–åçš„æ¶ˆæ¯æ–‡æœ¬
        """
        if "error" in results:
            return f"âŒ æœç´¢å¤±è´¥: {results['error']}"
        
        merged_by_type = results.get("merged_by_type", {})
        total = results.get("total", 0)
        
        if cloud_type not in merged_by_type or not merged_by_type[cloud_type]:
            return f"ğŸ” è¯¥ç±»å‹ä¸‹æš‚æ— èµ„æº"
        
        links = merged_by_type[cloud_type]
        type_name = CLOUD_TYPE_NAMES.get(cloud_type, cloud_type)
        icon = CLOUD_TYPE_ICONS.get(cloud_type, "ğŸ“")
        
        # åˆ†é¡µ
        total_pages = (len(links) + per_page - 1) // per_page
        start = (page - 1) * per_page
        end = start + per_page
        page_links = links[start:end]
        
        lines = [
            f"{icon} <b>{type_name}</b> - {keyword}",
            f"ğŸ“Š å…± {len(links)} æ¡ç»“æœ (ç¬¬{page}/{total_pages}é¡µ)\n"
        ]
        
        for i, link in enumerate(page_links, start + 1):
            url = link.get("url", "")
            password = link.get("password", "")
            note = link.get("note", "")
            source = link.get("source", "")
            
            clean_note = self._clean_text(note) if note else "æ— æ ‡é¢˜"
            
            lines.append(f"{i}. {clean_note}")
            lines.append(f"   ğŸ”— {url}")
            if password:
                lines.append(f"   ğŸ”‘ å¯†ç : <code>{password}</code>")
            if source:
                lines.append(f"   ğŸ“Œ æ¥æº: {source}")
            lines.append("")  # ç©ºè¡Œåˆ†éš”
        
        lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        lines.append("ğŸ’¡ æç¤º: ç‚¹å‡»é“¾æ¥å¯è®¿é—®ï¼Œé•¿æŒ‰å¯å¤åˆ¶")
        
        return "\n".join(lines)
    
    def format_results(self, results: Dict[str, Any], keyword: str) -> str:
        """
        æ ¼å¼åŒ–æ‰€æœ‰æœç´¢ç»“æœï¼ˆå¤‡ç”¨ï¼Œæ˜¾ç¤ºæ‰€æœ‰ç»“æœï¼‰
        """
        if "error" in results:
            return f"âŒ æœç´¢å¤±è´¥: {results['error']}"
        
        merged_by_type = results.get("merged_by_type", {})
        total = results.get("total", 0)
        
        if not merged_by_type or total == 0:
            return f"ğŸ” æœªæ‰¾åˆ°ä¸ã€Œ{keyword}ã€ç›¸å…³çš„èµ„æº"
        
        lines = [
            f"ğŸ” æœç´¢ç»“æœ: {keyword}",
            f"ğŸ“Š å…±æ‰¾åˆ° {total} æ¡ç»“æœ\n"
        ]
        
        for cloud_type, links in merged_by_type.items():
            if not links:
                continue
            
            type_name = CLOUD_TYPE_NAMES.get(cloud_type, cloud_type)
            lines.append(f"\nğŸ“ {type_name} ({len(links)}ä¸ª)")
            
            for i, link in enumerate(links[:5], 1):  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                url = link.get("url", "")
                password = link.get("password", "")
                note = link.get("note", "")
                source = link.get("source", "")
                
                clean_note = self._clean_text(note) if note else "æ— æ ‡é¢˜"
                
                lines.append(f"\n{i}. {clean_note}")
                lines.append(f"   ğŸ”— {url}")
                if password:
                    lines.append(f"   ğŸ”‘ å¯†ç : {password}")
                if source:
                    lines.append(f"   ğŸ“Œ æ¥æº: {source}")
        
        lines.append("\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        lines.append("ğŸ’¡ æç¤º: é•¿æŒ‰é“¾æ¥å¯å¤åˆ¶ï¼Œå¯†ç å¯æ‰‹åŠ¨å¤åˆ¶")
        
        return "\n".join(lines)


# å…¨å±€å®¢æˆ·ç«¯å®ä¾‹
pansou_client = PansouClient()
